# 如何集成其他的模型
DarwinKit 支持其他的模型通过集成 DarwinKit 的接口，来使用 DarwinKit 的特性。下面是一个简单的例子，展示如何集成一个简单的模型。
## 接入 Trainer API
### 定义模型
首先，我们需要定义一个简单的模型。我们可以使用 `torch.nn.Module` 类来定义一个简单的模型：
```python
import torch
import torch.nn as nn

class SimpleModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleModel, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```
观察上方模型，我可以提取出来一个 ModelConfig 的类，用于存储模型的配置信息：
```python
class SimpleModelConfig:
    def __init__(self, input_size, hidden_size, output_size):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
```
相应的模型代码修改为：
```python
import torch
import torch.nn as nn

class SimpleModel(nn.Module):
    def __init__(self, config):
        super(SimpleModel, self).__init__()
        self.fc1 = nn.Linear(config.input_size, config.hidden_size)
        self.fc2 = nn.Linear(config.hidden_size, config.output_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```

### 接入 DarwinKit 的 Trainer API
接下来，我们需要定义一个 Trainer 类，用于训练模型。我们需要继承 `DarwinKit` 的 `Trainer` 和 `TrainerConfig` 类来定义一个新的 `Trainer` 和 `TrainerConfig` 类：
```python
from DarwinKit.trainer import Trainer as BaseTrainer, TrainerConfig as BaseTrainerConfig

# 作为演示 TrainerConfig 只是简单的定义了几个参数
# 实际使用时，可以根据需要定义更多的参数
class TrainerConfig(BaseTrainerConfig):
    device = "cuda"
    lr = 1e-3
    batch_size = 12
    # 这些参数在 BaseTrainerConfig 中已经定义了
    # 是用于控制 Trainer API 预设的一些训练逻辑，比如保存 checkpoint，评估模型等
    max_step: int = 80000 * 16 # 定义最大训练步数
    eval_iters: int = 100 # 定义评估步数
    eval_step_interval: int = 1000 # 定义评估步数间隔
    save_step_interval: int = 10000 # 定义保存模型间隔

class Trainer(BaseTrainer):
    def __init__(self, model, tokenizer, config, **kwargs):
        super(Trainer, self).__init__(model, tokenizer, config, **kwargs)
    
    def train(self, train_dataset, val_dataset=None):
        # 在这里实现自定义的训练逻辑
        dataloader = DataLoader(train_dataset, batch_size=self.config.batch_size)
        val_dataloader = DataLoader(val_dataset, batch_size=self.config.batch_size)
        
        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.config.lr)

        for step, batch in enumerate(train_dataset):
            inputs, labels = batch
            outputs = self.model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            # 调用 Trainer 父类提供的保存和评估方法
            # 会根据 config 提供的参数来控制保存和评估的逻辑
            self._auto_validate(val_dataloader)
            self._auto_save_pretrained()
            self.current_step = step
    
    @torch.no_grad()
    def validate(self, val_dataloader) -> torch.Tensor:
        # 在这里实现自定义的评估逻辑
        loss = self.model.eval()
        return loss
```
通过以上的代码，我们定义了一个简单的 Trainer 类，用于训练模型。对于接入了 DarwinKit 的 Trainer API 的模型，提供了以下几个特性：
1. 自动保存模型，会根据 TrainerConfig 中的参数来控制保存模型的逻辑。模型会统一保存到 `DSPIKE_HOME/model.name` 路径下, 并且会根据模型保存时的进度来命名，比如 `iter-10000-ckpt.pth`。
2. 保存模型的配置信息和训练的配置信息到 `config.json` 和 `trainer_config.json` 文件中。
3. 保存模型使用的 tokenizer 到 `tokenizer.json` 文件中。
4. 自动评估模型，会根据 TrainerConfig 中的参数来控制评估模型的逻辑。

### 接入 Predicter API
如果需要使用模型进行预测，可以使用 `Predicter` 类。`Predicter` 类主要的作用就是根据模型 name 自动的加载模型和 Tokenizer，并且提供了一个 `predict` 方法，用于预测输入的数据。`Predicter` 类的定义如下：

```python
from DarwinKit.predicter import Predicter as BasePredicter

class Predicter(BasePredicter):
    def __init__(self, model_name, model_path=None, tokenizer_path=None):
        super(Predicter, self).__init__(model_name, model_path, tokenizer_path)

    @classmethod
    def get_model(cls, checkpoint: Optional[str] = None):
        # 在这里实现自定义的获取模型的逻辑
        checkpoint_path = cls.get_checkpoint(name, checkpoint)
        config_dict = cls.get_model_config_json(name)
        config = GPTConfig(**config_dict)
        checkpoint_dict = torch.load(checkpoint_path, weights_only=True)
        model.load_state_dict(checkpoint_dict["model"], strict=True)
        return model
    
    # 可选
    def predict(self, inputs):
        # 在这里实现自定义的预测逻辑
        outputs = self.model(inputs)
        return outputs
```

## 高级功能
### 自定义 log
Trainer API 除了提供上述的功能外，基于其他简单配置还可以实现 log 功能，用于记录训练过程中的一些信息，比如训练损失等信息, 并且高度支持自定义。并且 DarwinKit 也提供了网页端的可视化工具，用于查看训练过程中的信息。
### 集成方法
需要定义一个 `LogFieldnames` 类，用于存储 log 的字段名。比如要记录最常见的训练损失，我们就需要定义 step 和 train_loss 两个字段，这样每一组 `LogFieldnames` 数据就代表当前 step 的 train_loss 。并且在 `Trainer.__init__` 方法中需要将该类传入父类的 `__init__` 方法中： 
```python
@dataclass
class LogFieldnames:
    step: int = 0
    train_loss: float = 0.0

class Trainer(BaseTrainer):
    def __init__(self, model, tokenizer, config, **kwargs):
        super(Trainer, self).__init__(
            model, tokenizer, config, log_fieldnames=LogFieldnames, **kwargs)
        ...
```
使用的话只需要在训练中调用 `self.csv_logger.log` 方法即可：
```python
class Trainer(BaseTrainer):
    def __init__(self, model, tokenizer, config, **kwargs):
        super(Trainer, self).__init__(
            model, tokenizer, config, log_fieldnames=LogFieldnames, **kwargs)
        ...
    def train(self, train_dataset, val_dataset=None):
        ...
        for step, batch in enumerate(train_dataset):
            ...
            loss = criterion(outputs, labels)
            log_fieldnames = LogFieldnames(
                step=step,
                train_loss=loss,
            )
            self.csv_logger.log(log_fieldnames)
            ...
```
这样 Trainer 就会在训练过程中把记录的 LogFieldnames 信息保存到 `DSPIKE_HOME/model.name/train_log.csv` 文件中。
#### 可视化 train log
如果查看记录 log 的可视化图表，可以使用 `DarwinKit` 提供的可视化工具。可视化工具会在后台启动一个 web 服务，读取 `train_log.csv` 文件中的数据，并且提供一个 web 页面用于查看 log 数据。

为了让图表展示我们关心的数据，需要在 Trainer 中定义要显示的图表的系列名和对应的 x，y 轴的字段名，比如我们要显示训练损失，就需要指定系列名为 train_loss， x 轴为 step，y 轴为 train_loss：

```python
class Trainer(BaseTrainer):
    _visual_series = {"train_loss": ["step", "train_loss"]}

    def __init__(self, model, tokenizer, config, **kwargs):
        ...
```

要启动可视化工具有两种办法，一种是通过 CLI 来启动：
```bash
DarwinKit start
```
另一种是在模型训练的时候通过 `enable_server` 参数来控制是否启动：
```python
trainer = Trainer(model, tokenizer, config, enable_server=True)
...
```
无论通过哪种方式时启动可视化页面，均可以查看之前已经训练好的模型的 log 数据。也可以查看当前正在训练的模型的 log 数据，当查看当前正在训练的模型的 log 数据时，会实时更新数据。

## 集成 DarwinKit 的优势
相比于直接使用模型网络训练，集成 DarwinKit ，可以获得以下优势：
1. 方便的与不同的数据集和标记化器集成。
2. 提供内置的数据集预处理方法。
3. 自动保存模型，无需手动保存模型，避免因为忘记保存模型而导致的模型丢失。
4. 保存模型权重的同时会保存模型的配置信息，避免因为模型配置信息丢失而导致的模型无法使用。以及方便不同配置的训练效果的对比。
5. 自动评估模型，无需手动设置评估模型的循环。
6. 提供内置的 log 工具，将训练期间的数据记录到文件中，方便后续查看。
7. 提供 WEB 网页，可以查看训练中和训练完成的模型的数据，对比不同模型的参数和训练效果，实时查看训练过程中的数据。
    ![查看已经训练完成和训练中的模型](/static/docs/model_select.png)
    ![对比模型的损失曲线](/static/docs/loss_chart.png)