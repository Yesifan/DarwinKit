---
title: 如何集成模型
authors:
  - "Yesifan@yesifan66@zju.edu.cn"
updated: "2025-01-13"
---
# 如何集模型
DarwinKit 支持其他的模型通过集成 DarwinKit 的接口，来使用 DarwinKit 的特性。下面是一个简单的例子，展示如何集成一个简单的模型。
## 接入 Trainer API
### 定义模型
首先，我们需要定义一个简单的模型。我们可以使用 `torch.nn.Module` 类来定义一个简单的模型：
```python
import torch
import torch.nn as nn
from dataclasses import dataclass
from pathlib import Path

@dataclass
class MyModelConfig:
    input_size:int = 12
    hidden_size:int = 12
    output_size:int = 12

class MyModel(nn.Module):
    def __init__(self, config:MyModelConfig):
        super(MyModel, self).__init__()
        self.config = config
        self.fc1 = nn.Linear(config.input_size, config.hidden_size)
        self.fc2 = nn.Linear(config.hidden_size, config.output_size)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```


### 接入 DarwinKit 的 Trainer API
接下来，我们需要定义一个 Trainer 类，用于训练模型。我们需要继承 `DarwinKit` 的 `Trainer` 和 `TrainerConfig` 类来定义一个新的 `Trainer` 和 `TrainerConfig` 类：
```python
import random
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm
from darkit.core import Trainer, TrainerConfig

from typing import Optional

print(f"model_cache_path: {model_cache_path}")

@dataclass
class MyTrainerConfig(TrainerConfig):
    device = "cuda"
    lr = 1e-3
    batch_size = 4
    max_step: int = 10000 # 定义最大训练步数
    save_step_interval: int = 10000 # 定义保存模型间隔


class MyTrainer(Trainer):
    def __init__(self, model:MyModel, config:MyTrainerConfig, **kwargs):
        super().__init__(model, config, **kwargs)
        self.config = config

    def _get_optimizer(self):
        return torch.optim.Adam(self.model.parameters(), lr=self.config.lr)
    
    def train(self, train_dataset, val_dataset=None):
        # 在这里实现自定义的训练逻辑
        dataloader = DataLoader(train_dataset, batch_size=self.config.batch_size)
        
        self.optimizer = self._get_optimizer()
        for step, batch in tqdm(enumerate(dataloader)):
            inputs, labels = batch
            inputs = inputs.to(self.config.device)
            labels = labels.to(self.config.device)

            outputs = self.model(inputs)
            loss = F.mse_loss(outputs, labels)
            loss.backward()
            self.optimizer.step()
            
            # 调用 Trainer 父类提供的保存和评估方法
            # 会根据 config 提供的参数来控制保存和评估的逻辑
            self.current_step = step
            self._auto_save_pretrained()

Trainer.register(MyModel.__name__, MyTrainer)
```
通过以上的代码，我们定义了一个简单的 Trainer 类，用于训练模型。对于接入了 DarwinKit 的 Trainer API 的模型，提供了以下几个特性：
1. 自动保存模型，会根据 TrainerConfig 中的参数来控制保存模型的逻辑。模型会统一保存到 `DARWIN_KIT_HOME/base/{model.name}` 路径下, 并且会根据模型保存时的进度来命名，比如 `iter-10000-ckpt.pth`。
2. 保存模型的配置信息和训练的配置信息到 `config.json` 和 `trainer_config.json` 文件中。
3. 保存模型使用的 tokenizer 到 `tokenizer.json` 文件中。
4. 自动评估模型，会根据 TrainerConfig 中的参数来控制评估模型的逻辑。

### 接入 Predicter API
如果需要使用模型进行预测，可以使用 `Predicter` 类。`Predicter` 类主要的作用就是根据模型 name 自动的加载模型和 Tokenizer，并且提供了一个 `predict` 方法，用于预测输入的数据。`Predicter` 类的定义如下：

```python
from darkit.core import Predicter

class MyPredicter(Predicter):
    def __init__(self, name, model, device="cpu"):
        super().__init__(name, model, device)
    
    @classmethod
    def get_model(cls, name:str, checkpoint: Optional[str] = None):
        # 在这里实现自定义的获取模型的逻辑
        checkpoint_path = cls.get_checkpoint(name, checkpoint)
        config_dict = cls.get_model_config_json(name)
        config = MyModelConfig(**config_dict)
        model = MyModel(config=config)
        checkpoint_dict = torch.load(checkpoint_path, weights_only=True)
        model.load_state_dict(checkpoint_dict["state_dict"], strict=True)
        return model
    
    def predict(self, input):
        input = input.to(self.device)
        output = self.model(input)
        return output
    
MyPredicter.register(MyModel.__name__, MyPredicter)
```

完整代码可以参考[这里](../3.Examples/1.Simple-example.md)。

## 高级功能
### 自定义 log
Trainer API 除了提供上述的功能外，基于其他简单配置还可以实现 log 功能，用于记录训练过程中的一些信息，比如训练损失等信息, 并且高度支持自定义。并且 DarwinKit 也提供了网页端的可视化工具，用于查看训练过程中的信息。
### 集成方法
需要定义一个 `LogFieldnames` 类，用于存储 log 的字段名。比如要记录最常见的训练损失，我们就需要定义 step 和 train_loss 两个字段，这样每一组 `LogFieldnames` 数据就代表当前 step 的 train_loss 。并且在 `Trainer.__init__` 方法中需要将该类传入父类的 `__init__` 方法中： 
```python
@dataclass
class LogFieldnames:
    step: int = 0
    train_loss: float = 0.0

class Trainer(BaseTrainer):
    def __init__(self, model, tokenizer, config, **kwargs):
        super(Trainer, self).__init__(
            model, tokenizer, config, log_fieldnames=LogFieldnames, **kwargs)
        ...
```
使用的话只需要在训练中调用 `self.csv_logger.log` 方法即可：
```python
class Trainer(BaseTrainer):
    def __init__(self, model, tokenizer, config, **kwargs):
        super(Trainer, self).__init__(
            model, tokenizer, config, log_fieldnames=LogFieldnames, **kwargs)
        ...
    def train(self, train_dataset, val_dataset=None):
        ...
        for step, batch in enumerate(train_dataset):
            ...
            loss = criterion(outputs, labels)
            log_fieldnames = LogFieldnames(
                step=step,
                train_loss=loss,
            )
            self.csv_logger.log(log_fieldnames)
            ...
```
这样 Trainer 就会在训练过程中把记录的 LogFieldnames 信息保存到 `DSPIKE_HOME/model.name/train_log.csv` 文件中。
#### 可视化 train log
如果查看记录 log 的可视化图表，可以使用 `DarwinKit` 提供的可视化工具。可视化工具会在后台启动一个 web 服务，读取 `train_log.csv` 文件中的数据，并且提供一个 web 页面用于查看 log 数据。

为了让图表展示我们关心的数据，需要在 Trainer 中定义要显示的图表的系列名和对应的 x，y 轴的字段名，比如我们要显示训练损失，就需要指定系列名为 train_loss， x 轴为 step，y 轴为 train_loss：

```python
class Trainer(BaseTrainer):
    _visual_series = {"train_loss": ["step", "train_loss"]}

    def __init__(self, model, tokenizer, config, **kwargs):
        ...
```

要启动可视化工具有两种办法，一种是通过 CLI 来启动：
```bash
DarwinKit start
```
另一种是在模型训练的时候通过 `enable_server` 参数来控制是否启动：
```python
trainer = Trainer(model, tokenizer, config, enable_server=True)
...
```
无论通过哪种方式时启动可视化页面，均可以查看之前已经训练好的模型的 log 数据。也可以查看当前正在训练的模型的 log 数据，当查看当前正在训练的模型的 log 数据时，会实时更新数据。

## 集成 DarwinKit 的优势
相比于直接使用模型网络训练，集成 DarwinKit ，可以获得以下优势：
1. 方便的与不同的数据集和标记化器集成。
2. 提供内置的数据集预处理方法。
3. 自动保存模型，无需手动保存模型，避免因为忘记保存模型而导致的模型丢失。
4. 保存模型权重的同时会保存模型的配置信息，避免因为模型配置信息丢失而导致的模型无法使用。以及方便不同配置的训练效果的对比。
5. 自动评估模型，无需手动设置评估模型的循环。
6. 提供内置的 log 工具，将训练期间的数据记录到文件中，方便后续查看。
7. 提供 WEB 网页，可以查看训练中和训练完成的模型的数据，对比不同模型的参数和训练效果，实时查看训练过程中的数据。
    ![查看已经训练完成和训练中的模型](/static/docs/model_select.png)
    ![对比模型的损失曲线](/static/docs/loss_chart.png)