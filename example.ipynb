{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /home/leinao/code/Dspike2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 获取当前工作目录\n",
    "notebook_dir = Path(os.getcwd())\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MyModelConfig:\n",
    "    input_size:int = 12\n",
    "    hidden_size:int = 12\n",
    "    output_size:int = 12\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, config:MyModelConfig):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.fc1 = nn.Linear(config.input_size, config.hidden_size)\n",
    "        self.fc2 = nn.Linear(config.hidden_size, config.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_cache_path: /home/leinao/code/Dspike2/.cache\n",
      "{'name': 'TEST_MODEL_71', 'max_step': 10000, 'save_step_interval': 10000}\n",
      "Save failed: source code not available\n",
      "Logger initialized at /home/leinao/code/Dspike2/.cache/TEST_MODEL_71/train_log.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3539563/3213859862.py:71: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = [(torch.tensor(x), torch.tensor(y)) for _ in range(4*10000)]\n",
      "10000it [00:02, 3811.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at /home/leinao/code/Dspike2/.cache/TEST_MODEL_71\n",
      "Model saved epoch 10000/10000 at iter-10000-ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from darkit.core import Trainer, TrainerConfig\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "model_cache_path = notebook_dir / '.cache'\n",
    "\n",
    "if not model_cache_path.exists():\n",
    "    model_cache_path.mkdir()\n",
    "\n",
    "print(f\"model_cache_path: {model_cache_path}\")\n",
    "\n",
    "@dataclass\n",
    "class MyTrainerConfig(TrainerConfig):\n",
    "    device = \"cuda\"\n",
    "    lr = 1e-3\n",
    "    batch_size = 4\n",
    "    max_step: int = 10000 # 定义最大训练步数\n",
    "    save_step_interval: int = 10000 # 定义保存模型间隔\n",
    "\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, model:MyModel, config:MyTrainerConfig, **kwargs):\n",
    "        super(MyTrainer, self).__init__(model, config, **kwargs)\n",
    "        self.config = config\n",
    "    \n",
    "    @property\n",
    "    def save_directory(self) -> Optional[Path]:\n",
    "        model_name = self.config.name\n",
    "        if model_name is not None and self._is_master_process():\n",
    "            save_directory = model_cache_path / model_name\n",
    "            return save_directory\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _get_optimizer(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.config.lr)\n",
    "    \n",
    "    def train(self, train_dataset, val_dataset=None):\n",
    "        # 在这里实现自定义的训练逻辑\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.config.batch_size)\n",
    "        \n",
    "        optimizer = self._get_optimizer()\n",
    "        for step, batch in tqdm(enumerate(dataloader)):\n",
    "            inputs, labels = batch\n",
    "            outputs = self.model(inputs)\n",
    "            loss = F.mse_loss(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 调用 Trainer 父类提供的保存和评估方法\n",
    "            # 会根据 config 提供的参数来控制保存和评估的逻辑\n",
    "            self.current_step = step\n",
    "            self._auto_save_pretrained()\n",
    "\n",
    "Trainer.register(MyModel.__name__, MyTrainer)\n",
    "\n",
    "name = f\"TEST_MODEL_{random.randint(10,99)}\"\n",
    "mconf = MyModelConfig()\n",
    "model = MyModel(mconf)\n",
    "tconf = MyTrainerConfig(name=name)\n",
    "trainer = MyTrainer(model, tconf)\n",
    "\n",
    "# 生成一些随机数据\n",
    "x = torch.randn(12)\n",
    "y = torch.randn(12)\n",
    "train_dataset = [(torch.tensor(x), torch.tensor(y)) for _ in range(4*10000)]\n",
    "\n",
    "trainer.train(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_directory /home/leinao/code/Dspike2/.cache/TEST_MODEL_71\n",
      "save_directory /home/leinao/code/Dspike2/.cache/TEST_MODEL_71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0915,  0.3169,  0.0660,  0.2210,  0.5283,  0.2934, -0.2829,  0.4491,\n",
       "         0.5927, -1.0472,  1.7596,  0.1983], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from darkit.core import Predicter\n",
    "\n",
    "class MyPredicter(Predicter):\n",
    "    def __init__(self, name, model, device=\"cpu\"):\n",
    "        super(MyPredicter, self).__init__(name, model, device)\n",
    "        self.model = self.model.to(self.device)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_save_directory(cls, model_name) -> Path:\n",
    "        save_directory = model_cache_path / model_name\n",
    "        return save_directory\n",
    "    \n",
    "    @classmethod\n",
    "    def get_model(cls, name:str, checkpoint: Optional[str] = None):\n",
    "        # 在这里实现自定义的获取模型的逻辑\n",
    "        checkpoint_path = cls.get_checkpoint(name, checkpoint)\n",
    "        config_dict = cls.get_model_config_json(name)\n",
    "        config = MyModelConfig(**config_dict)\n",
    "        model = MyModel(config=config)\n",
    "        checkpoint_dict = torch.load(checkpoint_path, weights_only=True)\n",
    "        model.load_state_dict(checkpoint_dict[\"model\"], strict=True)\n",
    "        return model\n",
    "    \n",
    "    def predict(self, input):\n",
    "        input = input.to(self.device)\n",
    "        output = self.model(input)\n",
    "        return output\n",
    "    \n",
    "Predicter.register(MyModel.__name__, MyPredicter)\n",
    "\n",
    "predicter = MyPredicter.from_pretrained(name)\n",
    "predicter.predict(torch.randn(12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspike2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
